{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fc2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from glob import glob\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from pickle import load\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f163f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = r'D:\\datasets\\ecti2021'\n",
    "train_dir = os.path.join(dataset_root, 'train/train')\n",
    "test_dir = os.path.join(dataset_root, 'val_without_ref_labels/val')\n",
    "\n",
    "n_train_regions = len(glob(os.path.join(train_dir, '*')))\n",
    "n_test_regions  = len(glob(os.path.join(test_dir, '*')))\n",
    "\n",
    "print('Number of training temporal-regions: {}'.format(n_train_regions))\n",
    "print('Number of test temporal-regions: {}'.format(n_test_regions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bd1bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(filepath,split_symbol='\\\\'):\n",
    "    return filepath.split(split_symbol)[-1]\n",
    "\n",
    "def read_csv(csvpath):\n",
    "    path_list = np.loadtxt(csvpath, delimiter=\" \", dtype=str).tolist()\n",
    "    return [os.path.basename(p) for p in path_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa7dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(df_row, figsize=[25, 15]):\n",
    "    vv_image_path = df_row['vv_image_path']\n",
    "    vh_image_path = df_row['vh_image_path']\n",
    "    flood_label_path = df_row['flood_label_path']\n",
    "    water_body_label_path = df_row['water_body_label_path']\n",
    "\n",
    "    rgb_name = get_filename(vv_image_path)\n",
    "    vv_image = cv2.imread(vv_image_path, 0) / 255.0\n",
    "    vh_image = cv2.imread(vh_image_path, 0) / 255.0\n",
    "    rgb_image = s1_to_rgb(vv_image, vh_image)\n",
    "\n",
    "    water_body_label_image = cv2.imread(water_body_label_path, 0) / 255.0\n",
    "\n",
    "    plt.figure(figsize=tuple(figsize))\n",
    "    if df_row.isnull().sum() > 0:\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(rgb_image)\n",
    "        plt.title(rgb_name)\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(water_body_label_image)\n",
    "        plt.title('Water body mask')\n",
    "    else:\n",
    "        flood_label_image = cv2.imread(flood_label_path, 0) / 255.0\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(rgb_image)\n",
    "        plt.title(rgb_name)\n",
    "\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(flood_label_image)\n",
    "        plt.title('Flood mask')\n",
    "\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(water_body_label_image)\n",
    "        plt.title('Water body mask')\n",
    "\n",
    "def s1_to_rgb(vv_image, vh_image):\n",
    "    eps=1e-06\n",
    "    ratio_image = np.clip(np.nan_to_num(vv_image/(vh_image+eps), 0), 0, 1) # outside [0,1] will be clipped\n",
    "    rgb_image = np.stack((vv_image, vh_image, ratio_image), axis=2) #different from lab01: np.abs(red) / np.abs(green) \n",
    "    return rgb_image\n",
    "\n",
    "def visualize_result(df_row, prediction, figsize=[25, 15]):\n",
    "    vv_image = cv2.imread(df_row['vv_image_path'], 0) / 255.0\n",
    "    vh_image = cv2.imread(df_row['vh_image_path'], 0) / 255.0\n",
    "    rgb_input = s1_to_rgb(vv_image, vh_image)\n",
    "\n",
    "    plt.figure(figsize=tuple(figsize))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(rgb_input)\n",
    "    plt.title('RGB w/ result')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(prediction)\n",
    "    plt.title('Result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3139261",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_image_names = read_csv(r'D:\\datasets/ecti2021\\water_tiles.csv')     \n",
    "\n",
    "background_image_names = read_csv(r\"D:\\datasets\\ecti2021\\background_tiles.csv\")\n",
    "\n",
    "region_name_dates0 = ['_'.join(os.path.basename(n).split('_')[:2]) for n in water_image_names]\n",
    "region_name_dates1 = ['_'.join(os.path.basename(n).split('_')[:2]) for n in background_image_names]\n",
    "\n",
    "vv_image_paths, vh_image_paths, flood_label_paths, water_body_label_paths = [], [], [], []\n",
    "\n",
    "water_image_paths,background_image_paths = [],[]\n",
    "\n",
    "for i in range(len(water_image_names)):\n",
    "    vv_image_path = os.path.join(train_dir, region_name_dates0[i], 'tiles', 'vv', water_image_names[i])\n",
    "    vv_image_paths.append(vv_image_path)\n",
    "    water_image_paths.append(vv_image_path)\n",
    "    \n",
    "    vh_image_name = water_image_names[i].replace('vv', 'vh')\n",
    "    vh_image_path = os.path.join(train_dir, region_name_dates0[i], 'tiles', 'vh', vh_image_name)\n",
    "    vh_image_paths.append(vh_image_path)\n",
    "\n",
    "    flood_image_name = water_image_names[i].replace('_vv', '')\n",
    "    flood_label_path = os.path.join(train_dir, region_name_dates0[i], 'tiles', 'flood_label', flood_image_name)\n",
    "    flood_label_paths.append(flood_label_path)\n",
    "\n",
    "    water_body_label_name = water_image_names[i].replace('_vv', '')\n",
    "    water_body_label_path = os.path.join(train_dir, region_name_dates0[i], 'tiles', 'water_body_label', water_body_label_name)\n",
    "    water_body_label_paths.append(water_body_label_path)\n",
    "    \n",
    "for i in range(len(background_image_names)):\n",
    "    vv_image_path = os.path.join(train_dir, region_name_dates1[i], 'tiles', 'vv', background_image_names[i])\n",
    "    vv_image_paths.append(vv_image_path)\n",
    "    background_image_paths.append(vv_image_path)\n",
    "    \n",
    "    vh_image_name = background_image_names[i].replace('vv', 'vh')\n",
    "    vh_image_path = os.path.join(train_dir, region_name_dates1[i], 'tiles', 'vh', vh_image_name)\n",
    "    vh_image_paths.append(vh_image_path)\n",
    "\n",
    "    flood_image_name = background_image_names[i].replace('_vv', '')\n",
    "    flood_label_path = os.path.join(train_dir, region_name_dates1[i], 'tiles', 'flood_label', flood_image_name)\n",
    "    flood_label_paths.append(flood_label_path)\n",
    "\n",
    "    water_body_label_name = background_image_names[i].replace('_vv', '')\n",
    "    water_body_label_path = os.path.join(train_dir, region_name_dates1[i], 'tiles', 'water_body_label', water_body_label_name)\n",
    "    water_body_label_paths.append(water_body_label_path)\n",
    "\n",
    "print(os.path.exists(vv_image_paths[0]))\n",
    "print(water_image_names[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6985d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(vv_image_paths)\n",
    "indices = np.arange(n)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_end = int(0.7 * n)\n",
    "valid_end = int(0.85 * n)\n",
    "\n",
    "train_idx = indices[:train_end]\n",
    "valid_idx = indices[train_end:valid_end]\n",
    "test_idx  = indices[valid_end:]\n",
    "print(\"Number of tiles in training set:\",train_idx.size)\n",
    "print(\"Number of tiles in validation set:\",valid_idx.size)\n",
    "print(\"Number of tiles in test set:\",test_idx.size)\n",
    "print(\"Number of tiles in the training and validation set:\",train_idx.size+valid_idx.size+test_idx.size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3c9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_image_paths_train = list(np.array(vv_image_paths)[train_idx])\n",
    "vh_image_paths_train = list(np.array(vh_image_paths)[train_idx])\n",
    "flood_label_paths_train = list(np.array(flood_label_paths)[train_idx])\n",
    "water_body_label_paths_train = list(np.array(water_body_label_paths)[train_idx])\n",
    "\n",
    "train_paths = {'vv_image_path': vv_image_paths_train,\n",
    "        'vh_image_path': vh_image_paths_train,\n",
    "        'flood_label_path': flood_label_paths_train,\n",
    "        'water_body_label_path': water_body_label_paths_train,\n",
    "}\n",
    "\n",
    "train_df = pd.DataFrame(train_paths)\n",
    "\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736b0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('max_colwidth',200)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcae5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_image_paths_valid = list(np.array(vv_image_paths)[valid_idx])\n",
    "vh_image_paths_valid = list(np.array(vh_image_paths)[valid_idx])\n",
    "flood_label_paths_valid = list(np.array(flood_label_paths)[valid_idx])\n",
    "water_body_label_paths_valid = list(np.array(water_body_label_paths)[valid_idx])\n",
    "\n",
    "valid_paths = {'vv_image_path': vv_image_paths_valid,\n",
    "        'vh_image_path': vh_image_paths_valid,\n",
    "        'flood_label_path': flood_label_paths_valid,\n",
    "        'water_body_label_path': water_body_label_paths_valid,\n",
    "}\n",
    "\n",
    "\n",
    "valid_df = pd.DataFrame(valid_paths)\n",
    "\n",
    "print(valid_df.shape)\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e84916",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({\n",
    "    'vv_image_path': np.array(vv_image_paths)[test_idx],\n",
    "    'vh_image_path': np.array(vh_image_paths)[test_idx],\n",
    "    'flood_label_path': np.array(flood_label_paths)[test_idx],\n",
    "    'water_body_label_path': np.array(water_body_label_paths)[test_idx],\n",
    "})\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef22f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_image_paths_train = [path for path in background_image_paths if path in vv_image_paths_train]\n",
    "background_num_train = len(background_image_paths_train)\n",
    "print('Number of background tiles included in training:',background_num_train)\n",
    "\n",
    "water_image_paths_train = [path for path in water_image_paths if path in vv_image_paths_train]\n",
    "water_image_names_train = [get_filename(pth) for pth in water_image_paths_train]\n",
    "region_name_dates2 = ['_'.join(n.split('_')[:2]) for n in water_image_names_train]\n",
    "water_num_train = len(water_image_paths_train)\n",
    "print('Number of water tiles included in training:',water_num_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = water_num_train\n",
    "arr = np.arange(int(water_num_train)) \n",
    "np.random.shuffle(arr) \n",
    "background_image_paths_train_undersampled = list(np.array(background_image_paths_train)[arr[0:num_samples]])\n",
    "background_image_names_train_undersampled = [get_filename(pth) for pth in background_image_paths_train_undersampled]\n",
    "print('Number of background tiles included in training after undersampling:',len(background_image_names_train_undersampled))\n",
    "region_name_dates3 = ['_'.join(n.split('_')[:2]) for n in background_image_names_train_undersampled]\n",
    "\n",
    "vh_image_paths_train_undersampled, flood_label_paths_train_undersampled, water_body_label_paths_train_undersampled = [], [], []\n",
    "for i in range(len(water_image_names_train)):\n",
    "    vh_image_name = water_image_names_train[i].replace('vv', 'vh')\n",
    "    vh_image_path = os.path.join(train_dir, region_name_dates2[i], 'tiles', 'vh', vh_image_name)\n",
    "    vh_image_paths_train_undersampled.append(vh_image_path)\n",
    "\n",
    "    flood_image_name = water_image_names_train[i].replace('_vv', '')\n",
    "    flood_label_path = os.path.join(train_dir, region_name_dates2[i], 'tiles', 'flood_label', flood_image_name)\n",
    "    flood_label_paths_train_undersampled.append(flood_label_path)\n",
    "\n",
    "    water_body_label_name = water_image_names_train[i].replace('_vv', '')\n",
    "    water_body_label_path = os.path.join(train_dir, region_name_dates2[i], 'tiles', 'water_body_label', water_body_label_name)\n",
    "    water_body_label_paths_train_undersampled.append(water_body_label_path)\n",
    "\n",
    "vv_image_paths_train_undersampled = water_image_paths_train\n",
    "print('Number of water body label included in training after undersampling:',len(water_body_label_paths_train_undersampled))\n",
    "for i in range(len(background_image_names_train_undersampled)):\n",
    "    vv_image_paths_train_undersampled.append(background_image_paths_train_undersampled[i])\n",
    "    \n",
    "    vh_image_name = background_image_names_train_undersampled[i].replace('vv', 'vh')\n",
    "    vh_image_path = os.path.join(train_dir, region_name_dates3[i], 'tiles', 'vh', vh_image_name)\n",
    "    vh_image_paths_train_undersampled.append(vh_image_path)\n",
    "\n",
    "    flood_image_name = background_image_names_train_undersampled[i].replace('_vv', '')\n",
    "    flood_label_path = os.path.join(train_dir, region_name_dates3[i], 'tiles', 'flood_label', flood_image_name)\n",
    "    flood_label_paths_train_undersampled.append(flood_label_path)\n",
    "\n",
    "    water_body_label_name = background_image_names_train_undersampled[i].replace('_vv', '')\n",
    "    water_body_label_path = os.path.join(train_dir, region_name_dates3[i], 'tiles', 'water_body_label', water_body_label_name)\n",
    "    water_body_label_paths_train_undersampled.append(water_body_label_path)\n",
    "assert len(vv_image_paths_train_undersampled)==len(vh_image_paths_train_undersampled)==len(flood_label_paths_train_undersampled)==len(water_body_label_paths_train_undersampled)\n",
    "print('Number of overall images  included in training after undersampling:',len(water_body_label_paths_train_undersampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9ff255",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths_undersample = {'vv_image_path': vv_image_paths_train_undersampled,\n",
    "        'vh_image_path': vh_image_paths_train_undersampled,\n",
    "        'flood_label_path': flood_label_paths_train_undersampled,\n",
    "        'water_body_label_path': water_body_label_paths_train_undersampled\n",
    "}\n",
    "train_df_undersample = pd.DataFrame(train_paths_undersample)\n",
    "\n",
    "\n",
    "MAX_TRAIN_SAMPLES = 1000  # or even 500 for POC\n",
    "\n",
    "train_df_undersample = train_df_undersample.sample(\n",
    "    n=min(MAX_TRAIN_SAMPLES, len(train_df_undersample)),\n",
    "    random_state=42\n",
    ").reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(train_df_undersample.shape)\n",
    "train_df_undersample.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21be5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_vv = train_df_undersample['vv_image_path'].isnull().sum()\n",
    "missing_vh = train_df_undersample['vh_image_path'].isnull().sum()\n",
    "print(f\"Missing Values for VV: {missing_vv}, VH: {missing_vh}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87583a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_counts = train_df_undersample['vv_image_path'].apply(lambda path: os.path.basename(path).split('_')[0]).value_counts(normalize=True)\n",
    "region_counts.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9c9b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = random.sample(range(len(train_df_undersample)), 3)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    sample_row = train_df_undersample.iloc[idx]\n",
    "    print(f\"Visualizing sample index: {idx}\")\n",
    "    visualize(sample_row)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETCIDataset(Dataset):\n",
    "    def __init__(self, dataframe, split, transform=None):\n",
    "        self.split = split\n",
    "        self.dataset = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example = {}\n",
    "        \n",
    "        df_row = self.dataset.iloc[index]\n",
    "\n",
    "        vv_image = cv2.imread(df_row['vv_image_path'], 0) / 255.0\n",
    "        vh_image = cv2.imread(df_row['vh_image_path'], 0) / 255.0\n",
    "        \n",
    "        rgb_image = s1_to_rgb(vv_image, vh_image)\n",
    "\n",
    "        if self.split == 'test':\n",
    "            example['image'] = rgb_image.transpose((2,0,1)).astype('float32')  #HWC->CHW\n",
    "        else:\n",
    "            flood_mask = cv2.imread(df_row['flood_label_path'], 0) / 255.0\n",
    "\n",
    "            \n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=rgb_image, mask=flood_mask)\n",
    "                rgb_image = augmented['image']\n",
    "                flood_mask = augmented['mask']\n",
    "\n",
    "            example['image'] = rgb_image.transpose((2,0,1)).astype('float32') #HWC->CHW\n",
    "            example['mask'] = flood_mask.astype('int64')\n",
    "\n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d857a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([A.Resize(height=192, width=192)])\n",
    "\n",
    "train_dataset = ETCIDataset(train_df, split='train', transform=train_transform)\n",
    "valid_dataset = ETCIDataset(valid_df, split='valid', transform=val_transform)  \n",
    "test_dataset  = ETCIDataset(test_df,  split='test',  transform=None)\n",
    "\n",
    "print('Trainining set size:',len(train_dataset))\n",
    "print('Validation set size:',len(valid_dataset))\n",
    "print('Test set size:',len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03fa1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=False)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cafb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_undersampled_dataset = ETCIDataset(train_df_undersample, split='train', transform=train_transform)\n",
    "train_undersampled_loader = DataLoader(train_undersampled_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=False)\n",
    "print('Undersampled Trainining set size:',len(train_undersampled_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        \n",
    "    encoder_weights=\"imagenet\",         \n",
    "    in_channels=3,                  \n",
    "    classes=2,                      \n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc03ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class EvalTracker:\n",
    "    def __init__(self, n_classes=2, smooth=0.0001):\n",
    "        self.n_classes = n_classes\n",
    "        self.reset()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def reset(self):\n",
    "        self.cm = np.zeros((self.n_classes, self.n_classes))\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, pred, target):\n",
    "        self.count += pred.shape[0]\n",
    "\n",
    "        pred = pred.argmax(dim=1).flatten()  # [B*H*W]\n",
    "        target = target.flatten()  # [B*H*W]\n",
    "\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        target = target.detach().cpu().numpy()\n",
    "\n",
    "        self.cm += confusion_matrix(target, pred)\n",
    "\n",
    "    def get_mean(self):\n",
    "        tn, fp, fn, tp = self.cm.ravel()\n",
    "\n",
    "        iou = tp / (tp + fp + fn + self.smooth)\n",
    "        prec = tp / (tp + fp + self.smooth)\n",
    "        rec = tp / (tp + fn + self.smooth)\n",
    "        f1 = 2.0*prec*rec/(prec+rec)\n",
    "\n",
    "        return iou, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8340f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "patience = 5          \n",
    "counter = 0           \n",
    "min_delta = 1e-4      \n",
    "epochs = 5\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1764d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = create_model()\n",
    "model_2 = model_2.to(device).to(memory_format=torch.channels_last)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model_2.parameters(),\n",
    "    lr=learning_rate,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "criteria_no_weights = nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e5e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_dict_2 = {}\n",
    "val_loss_dict_2 = {}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch: [{}/{}]'.format(epoch+1, epochs))\n",
    "\n",
    "    pbar = tqdm(train_undersampled_loader)\n",
    "    train_loss = 0.0\n",
    "    model_2.train()\n",
    "    eval_logger = EvalTracker()\n",
    "\n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        image = batch['image'].to(device, non_blocking=True)\\\n",
    "                              .to(memory_format=torch.channels_last)\n",
    "        mask = batch['mask'].to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        with autocast(device_type='cuda'):\n",
    "            pred = model_2(image)\n",
    "            loss = criteria_no_weights(pred, mask)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # ch·ªâ update metric m·ªói 10 batch (r·∫•t quan tr·ªçng)\n",
    "        if batch_idx % 10 == 0:\n",
    "            eval_logger.update(pred, mask)\n",
    "            mIoU, Prec, Rec, f1 = eval_logger.get_mean()\n",
    "            pbar.set_description(\n",
    "                f'Loss: {loss.item():.4f} | mIoU {mIoU:.4f} | F1 {f1:.4f}'\n",
    "            )\n",
    "        \n",
    "        train_loss += loss.detach() * image.size(0)\n",
    "        \n",
    "    train_loss /= len(train_undersampled_loader.dataset)\n",
    "    train_loss_dict_2[epoch] = train_loss.item()\n",
    "    \n",
    "    pbar = tqdm(valid_loader)\n",
    "    model_2.eval()\n",
    "    eval_logger = EvalTracker()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad(), autocast(device_type='cuda'):\n",
    "        for batch in pbar:\n",
    "            image = batch['image'].to(device, non_blocking=True)\\\n",
    "                                  .to(memory_format=torch.channels_last)\n",
    "            mask = batch['mask'].to(device, non_blocking=True).long()\n",
    "    \n",
    "            pred = model_2(image)\n",
    "            loss = criteria_no_weights(pred, mask)\n",
    "    \n",
    "            val_loss += loss.detach() * image.size(0)\n",
    "            eval_logger.update(pred, mask)\n",
    "    \n",
    "    val_loss /= len(valid_loader.dataset)\n",
    "    val_loss_dict_2[epoch] = val_loss.item()\n",
    "    \n",
    "    mIoU, Prec, Rec, f1 = eval_logger.get_mean()\n",
    "    \n",
    "    print(\n",
    "        f'[VAL] Epoch {epoch+1} | Loss: {val_loss:.4f} | mIoU {mIoU:.4f} | F1 {f1:.4f}'\n",
    "    )\n",
    "    if val_loss < best_val_loss - min_delta:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "    \n",
    "        # l∆∞u model t·ªët nh·∫•t\n",
    "        torch.save(model_2.state_dict(), 'best_model_2d_BCE.pt')\n",
    "        print('‚úÖ Validation loss improved ‚Üí save best model')\n",
    "    \n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f'‚è∏ No improvement: {counter}/{patience}')\n",
    "    \n",
    "    if counter >= patience:\n",
    "        print('üõë Early stopping triggered ‚Üí model has converged')\n",
    "        break\n",
    "with open('./train_loss_2d_BCE.pkl', 'wb') as f:\n",
    "    pickle.dump(train_loss_dict_2, f)\n",
    "\n",
    "with open('./val_loss_2d_BCE.pkl', 'wb') as f:\n",
    "    pickle.dump(val_loss_dict_2, f)\n",
    "\n",
    "# save model\n",
    "torch.save(model_2.state_dict(), 'model_2d_BCE.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40c3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(next(model_2.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233ef38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = create_model()\n",
    "model_test.load_state_dict(\n",
    "    torch.load('model_2d_BCE.pt', map_location=device)\n",
    ")\n",
    "model_test = model_test.to(device)\n",
    "model_test.eval()\n",
    "\n",
    "print(\"Final trained model loaded for inference\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b259d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model_test(image)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "print(\n",
    "    probs[0, 1].min().item(),\n",
    "    probs[0, 1].max().item(),\n",
    "    probs[0, 1].mean().item()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# pick 3 random validation samples\n",
    "sample_indices = random.sample(range(len(valid_df)), 3)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx in sample_indices:\n",
    "        row = valid_df.iloc[idx]\n",
    "\n",
    "        vv = cv2.imread(row['vv_image_path'], 0) / 255.0\n",
    "        vh = cv2.imread(row['vh_image_path'], 0) / 255.0\n",
    "        rgb = s1_to_rgb(vv, vh)\n",
    "\n",
    "        image = torch.tensor(\n",
    "            rgb.transpose(2,0,1),\n",
    "            dtype=torch.float32\n",
    "        ).unsqueeze(0).to(device)\n",
    "\n",
    "        with autocast(device_type='cuda'):\n",
    "            pred = model_test(image)\n",
    "            pred_mask = torch.argmax(pred, dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "        print(f\" Visualizing validation sample {idx}\")\n",
    "        visualize_result(row, pred_mask)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f236c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_undersampled_loader))\n",
    "print(batch['image'].shape, batch['mask'].shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
